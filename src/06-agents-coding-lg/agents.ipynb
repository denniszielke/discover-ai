{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt flow service...\n",
      "Start prompt flow service on 127.0.0.1:23333, version: 1.15.0.\n",
      "You can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import streamlit as st\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.callbacks.streamlit import (\n",
    "    StreamlitCallbackHandler,\n",
    ")\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from promptflow.tracing import start_trace\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "# start a trace session, and print a url for user to check trace\n",
    "start_trace()\n",
    "\n",
    "# enable langchain instrumentation\n",
    "from opentelemetry.instrumentation.langchain import LangchainInstrumentor\n",
    "instrumentor = LangchainInstrumentor()\n",
    "if not instrumentor.is_instrumented_by_opentelemetry:\n",
    "    instrumentor.instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: AzureChatOpenAI = None\n",
    "embeddings_model: AzureOpenAIEmbeddings = None\n",
    "if \"AZURE_OPENAI_API_KEY\" in os.environ:\n",
    "    model = AzureChatOpenAI(\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        azure_deployment=os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "        openai_api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        temperature=0,\n",
    "        streaming=False\n",
    "    )\n",
    "    embeddings_model = AzureOpenAIEmbeddings(    \n",
    "        azure_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "        openai_api_version = os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        model= os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    )\n",
    "else:\n",
    "    token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "    model = AzureChatOpenAI(\n",
    "        azure_ad_token_provider=token_provider,\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        azure_deployment=os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "        openai_api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        temperature=0,\n",
    "        openai_api_type=\"azure_ad\",\n",
    "        streaming=True\n",
    "    )\n",
    "    embeddings_model = AzureOpenAIEmbeddings(    \n",
    "        azure_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "        openai_api_version = os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        model= os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    "        azure_ad_token_provider = token_provider\n",
    "    )\n",
    "\n",
    "def llm(x):\n",
    "    return model.invoke(x).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, TypedDict, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "import random\n",
    "import time\n",
    "\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    feedback: Optional[str] = None\n",
    "    history: Optional[str] = None\n",
    "    code: Optional[str] = None\n",
    "    specialization: Optional[str]=None\n",
    "    rating: Optional[str] = None\n",
    "    iterations: Optional[int]=None\n",
    "    code_compare: Optional[str]=None\n",
    "    actual_code: Optional[str]=None\n",
    "\n",
    "workflow = StateGraph(GraphState)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_start= \"You are Code reviewer specialized in {}.\\\n",
    "You need to review the given code following PEP8 guidelines and potential bugs\\\n",
    "and point out issues as bullet list.\\\n",
    "Code:\\n {}\"\n",
    "\n",
    "coder_start = \"You are a Coder specialized in {}.\\\n",
    "Improve the given code given the following guidelines. Guideline:\\n {} \\n \\\n",
    "Code:\\n {} \\n \\\n",
    "Output just the improved code and nothing else.\"\n",
    "\n",
    "rating_start = \"Rate the skills of the coder on a scale of 10 given the Code review cycle with a short reason.\\\n",
    "Code review:\\n {} \\n \"\n",
    "\n",
    "code_comparison = \"Compare the two code snippets and rate on a scale of 10 to both. Dont output the codes. Revised Code: \\n {} \\n Actual Code: \\n {}\"\n",
    "\n",
    "classify_feedback = \"Are all feedback mentioned resolved in the code? Output just Yes or No.\\\n",
    "Code: \\n {} \\n Feedback: \\n {} \\n\"\n",
    "\n",
    "def handle_reviewer(state):\n",
    "    print(state)\n",
    "    history = state.get('history', '').strip()\n",
    "    code = state.get('code', '').strip()\n",
    "    specialization = state.get('specialization','').strip()\n",
    "    iterations = state.get('iterations')\n",
    "    \n",
    "    print(\"Reviewer working...\")\n",
    "    \n",
    "    feedback = llm(reviewer_start.format(specialization,code))\n",
    "    \n",
    "    return {'history':history+\"\\n REVIEWER:\\n\"+feedback,'feedback':feedback,'iterations':iterations+1}\n",
    "\n",
    "def handle_coder(state):\n",
    "    print(state)\n",
    "    history = state.get('history', '').strip()\n",
    "    feedback = state.get('feedback', '').strip()\n",
    "    code =  state.get('code','').strip()\n",
    "    specialization = state.get('specialization','').strip()\n",
    "    \n",
    "    print(\"CODER rewriting...\")\n",
    "    \n",
    "    code = llm(coder_start.format(specialization,feedback,code))\n",
    "    return {'history':history+'\\n CODER:\\n'+code,'code':code}\n",
    "\n",
    "def handle_result(state):\n",
    "    print(state)\n",
    "    print(\"Review done...\")\n",
    "    \n",
    "    history = state.get('history', '').strip()\n",
    "    code1 = state.get('code', '').strip()\n",
    "    code2 = state.get('actual_code', '').strip()\n",
    "    rating  = llm(rating_start.format(history))\n",
    "    \n",
    "    code_compare = llm(code_comparison.format(code1,code2))\n",
    "    return {'rating':rating,'code_compare':code_compare}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"handle_reviewer\",handle_reviewer)\n",
    "workflow.add_node(\"handle_coder\",handle_coder)\n",
    "workflow.add_node(\"handle_result\",handle_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deployment_ready(state):\n",
    "    deployment_ready = 1 if 'yes' in llm(classify_feedback.format(state.get('code'),state.get('feedback'))) else 0\n",
    "    total_iterations = 1 if state.get('iterations')>5 else 0\n",
    "    return \"handle_result\" if  deployment_ready or total_iterations else \"handle_coder\" \n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"handle_reviewer\",\n",
    "    deployment_ready,\n",
    "    {\n",
    "        \"handle_result\": \"handle_result\",\n",
    "        \"handle_coder\": \"handle_coder\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.set_entry_point(\"handle_reviewer\")\n",
    "workflow.add_edge('handle_coder', \"handle_reviewer\")\n",
    "workflow.add_edge('handle_result', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewer working...\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x15c43a7a9e93a3c9ea559bdf463e3077\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x58ebb26d94ba06d92224f82c08ba1ab1\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0xda1a77ec05265ebec603d620b840c43e\n",
      "CODER rewriting...\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x2d21842fae90807b55bbaaecbc6a3a1d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0xc4d086b7e2a2cf43a2fc5698b4508671\n",
      "Reviewer working...\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x058e4e376197c289aa7dd017ed71dfa0\n",
      "CODER rewriting...\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0xffe946792e46ad47aff5026579d62366\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x83c323ced917b65d99727949cc351e07\n",
      "Reviewer working...\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x0f826673d0e4369bc4fd9b473ca776b7\n",
      "CODER rewriting...\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x1bc0f81f95716dfdf4d9dd49cd016003\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0xbe12a675e6f4dbdf22c92aa1c16dbf0a\n",
      "Reviewer working...\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0xab85783710a973366007e1189a8e501a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0xa5cbd4a4f80531c1953d19bc7f860dac\n",
      "CODER rewriting...\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x52e0b6d7fa9cd3639df0afc1f332f3ae\n",
      "Reviewer working...\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x50b1885671b10f693c6c2114d8fa5473\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0xa26e7ebfe9c4c50643c013e1a7c48466\n",
      "CODER rewriting...\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x3f04be9b16ddf75d7a213e63cf0b69db\n",
      "Reviewer working...\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x717459ca5115c6d532daa8d640ff3849\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x1033b417c142eeefd1d5e723dc72561e\n",
      "Review done...\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0xf9889e9fa818c42d1f2b79a9ed7ebf9a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x12c5d297bb75077a6b426b2420dcb30d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=06-agents-coding-lg&uiTraceId=0x686dac4cda14abd815c1463b0f427505\n"
     ]
    }
   ],
   "source": [
    "specialization = 'python'\n",
    "problem = 'Generate code to train a Regression ML model using a tabular dataset following required preprocessing steps.'\n",
    "code = llm(problem)\n",
    "\n",
    "app = workflow.compile()\n",
    "conversation = app.invoke({\"history\":code,\"code\":code,'actual_code':code,\"specialization\":specialization,'iterations':0},{\"recursion_limit\":10})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discover-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
