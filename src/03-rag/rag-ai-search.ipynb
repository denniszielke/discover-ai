{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval augmented generation\n",
    "\n",
    "If not already done run this in the top level folder:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create vector search index\n",
    "\n",
    "Create your search index schema and vector search configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndex\n",
    "\n",
    ")\n",
    "\n",
    "credential = AzureKeyCredential(os.environ[\"AZURE_AI_SEARCH_KEY\"]) if len(os.environ[\"AZURE_AI_SEARCH_KEY\"]) > 0 else DefaultAzureCredential()\n",
    "\n",
    "index_name = \"movies-semantic-index\"\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"], \n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "# Create a search index with the fields and a vector field which we will fill with a vector based on the overview field\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"genre\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"year\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"rating\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"plot\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\"\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Configure the semantic search configuration to prefer title and tagline fields over overview\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"movies-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"genre\")],\n",
    "        content_fields=[SemanticField(field_name=\"plot\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load custom data\n",
    "Here's how you load custom data into an embedding model and how you use langchain to query it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "        api_version = os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "# use an embeddingsmodel to create embeddings\n",
    "def get_embedding(text, model=os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")):\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# 1. define function to parse csv row and create embedding for overview text\n",
    "def parseMovie(movie):\n",
    "    print(movie)\n",
    "    return dict([\n",
    "        (\"id\", str(movie[\"movie_id\"])),\n",
    "        (\"genre\", movie[\"movie_genre\"]),\n",
    "        (\"title\", movie[\"movie_title\"]),\n",
    "        (\"year\", str(movie[\"movie_year\"])),\n",
    "        (\"rating\", str(movie[\"movie_rating\"])),\n",
    "        (\"plot\", movie[\"movie_plot\"]),\n",
    "        (\"vector\", get_embedding(movie[\"movie_plot\"]))\n",
    "    ])\n",
    "\n",
    "# 2. load movies from csv\n",
    "movies = []\n",
    "with open('./movies.json') as json_data:\n",
    "    moviesJson = json.load(json_data)\n",
    "    line_count = 0\n",
    "    for movieJson in moviesJson:\n",
    "        movieEmbedding = parseMovie(movieJson)\n",
    "        movies.append(movieEmbedding)\n",
    "        line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n",
    "print('Loaded %s movies.' % len(movies))\n",
    "\n",
    "\n",
    "# 3. upload documents to vector store\n",
    "search_client = SearchClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"], \n",
    "    index_name=index_name,\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "result = search_client.upload_documents(movies)\n",
    "print(f\"Successfully loaded {len(movies)} movies into Azure AI Search index.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query index and create a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.search.documents.models import (\n",
    "    VectorizedQuery\n",
    ")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "        api_version = os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "model_name = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\")\n",
    "\n",
    "index_client = SearchClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"], \n",
    "    index_name=index_name,\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "question = \"Tell me about the latest Ant Man movie. When was it released?\"\n",
    "\n",
    "# create a vectorized query based on the question\n",
    "vector = VectorizedQuery(vector=get_embedding(question), k_nearest_neighbors=5, fields=\"vector\")\n",
    "\n",
    "\n",
    "# create search client to retrieve movies from the vector store\n",
    "found_docs = list(search_client.search(\n",
    "    search_text=None,\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name=\"movies-semantic-config\",\n",
    "    vector_queries=[vector],\n",
    "    select=[\"title\", \"genre\", \"plot\", \"year\"],\n",
    "    top=5\n",
    "))\n",
    "\n",
    "found_docs_as_text = \" \"\n",
    "# print the found documents and the field that were selected\n",
    "for doc in found_docs:\n",
    "    print(\"Movie: {}\".format(doc[\"title\"]))\n",
    "    print(\"Genre: {}\".format(doc[\"genre\"]))\n",
    "    print(\"Year: {}\".format(doc[\"year\"]))\n",
    "    print(\"----------\")\n",
    "    found_docs_as_text += \" \"+ \"Movie Title: {}\".format(doc[\"title\"]) +\" \"+ \"Release Year: {}\".format(doc[\"year\"]) + \" \"+ \"Movie Plot: {}\".format(doc[\"plot\"])\n",
    "    \n",
    "# augment the question with the found documents and ask the LLM to generate a response\n",
    "system_prompt = \"You are an assistant to the user, you are given some context below, please answer the query of the user with as much detail as possible\"\n",
    "\n",
    "parameters = [system_prompt, ' Context:', found_docs_as_text , ' Question:', question]\n",
    "joined_parameters = ''.join(parameters)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model = deployment_name,\n",
    "        messages = [{\"role\" : \"assistant\", \"content\" : joined_parameters}],\n",
    "    )\n",
    "\n",
    "print (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def ask_question(ask: str):\n",
    "    \"\"\"\n",
    "    Ask a question\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a vectorized query based on the question\n",
    "    vector = VectorizedQuery(vector=get_embedding(ask), k_nearest_neighbors=5, fields=\"vector\")\n",
    "\n",
    "\n",
    "    # create search client to retrieve movies from the vector store\n",
    "    found_docs = list(search_client.search(\n",
    "        search_text=None,\n",
    "        query_type=\"semantic\",\n",
    "        semantic_configuration_name=\"movies-semantic-config\",\n",
    "        vector_queries=[vector],\n",
    "        select=[\"title\", \"genre\", \"plot\"],\n",
    "        top=5\n",
    "    ))\n",
    "\n",
    "    # print the found documents and the field that were selected\n",
    "    for doc in found_docs:\n",
    "        print(\"Movie: {}\".format(doc[\"title\"]))\n",
    "        print(\"Genre: {}\".format(doc[\"genre\"]))\n",
    "        print(\"----------\")\n",
    "\n",
    "\n",
    "    found_docs_as_text = \" \"\n",
    "    for elem in enumerate(found_docs, start=1):    \n",
    "        found_docs_as_text += \" \"+ \"Movie Title: {}\".format(doc[\"title\"]) +\" \"+ \"Movie story: {}\".format(doc[\"plot\"])\n",
    "\n",
    "    # augment the question with the found documents and ask the LLM to generate a response\n",
    "    system_prompt = \"\"\"You are an assistant to the user, you are given some context below. Please answer the query of the user with as few words as possible. Answer only with the correct information and be as short as possible. If the response is about estimation just answer with the number. If the response is about multiple choice just respond with the value strings from the options. If the response is true or false just say True or False. Do not end the response with a point.\"\"\"\n",
    "\n",
    "    parameters = [system_prompt, ' Context:', found_docs_as_text , ' Question:', ask]\n",
    "    joined_parameters = ''.join(parameters)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model = deployment_name,\n",
    "            messages = [{\"role\" : \"assistant\", \"content\" : joined_parameters}],\n",
    "        )\n",
    "\n",
    "    print (response.choices[0].message.content)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this snippet to try your method with several questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "answer = await ask_question(\"How many actors were featured in The Smonger Games?\")\n",
    "print('Answer:', answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = await ask_question(\"Does 'The Lost City' have any sequels planned? True or False\")\n",
    "print('Answer:', answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discover-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
