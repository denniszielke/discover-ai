{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"embed.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display\n",
    "from itertools import combinations\n",
    "from PIL import Image\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version = os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "\n",
    "# use an embeddingsmodel to create embeddings\n",
    "def openai_text_embeddings(text, model=embedding_model):\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def text_comparison(vector1, vector2):\n",
    "    \"\"\"\n",
    "    Cosine similarity value between two embedded vectors\n",
    "    \"\"\"\n",
    "    if len(vector1) != len(vector2):\n",
    "        print(\"[Error] Vectors do not have the same size\")\n",
    "        return None\n",
    "\n",
    "    dot_product = sum(x * y for x, y in zip(vector1, vector2))\n",
    "    magnitude1 = math.sqrt(sum(x * x for x in vector1))\n",
    "    magnitude2 = math.sqrt(sum(x * x for x in vector2))\n",
    "    cosine_similarity = round(dot_product / (magnitude1 * magnitude2), 15)\n",
    "\n",
    "    # Or we can use directly the cosine_similarity function from Open AI\n",
    "\n",
    "    if cosine_similarity == 1:\n",
    "        decision = \"identical\"\n",
    "        color_code = \"\\033[1;31;34m\"\n",
    "        emoticon = emoji.emojize(\":red_heart:\")\n",
    "\n",
    "    elif cosine_similarity >= 0.8:\n",
    "        decision = \"similar semantic\"\n",
    "        color_code = \"\\033[1;31;32m\"\n",
    "        emoticon = emoji.emojize(\":thumbs_up:\")\n",
    "\n",
    "    else:\n",
    "        decision = \"different\"\n",
    "        color_code = \"\\033[1;31;91m\"\n",
    "        emoticon = emoji.emojize(\":fire:\")\n",
    "\n",
    "    print(\n",
    "        f\"{emoticon} {color_code}{decision.upper()} text (cosine similarity = {cosine_similarity})\"\n",
    "    )\n",
    "    print(\"\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text embeddings with Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello. Good morning!\"\n",
    "emb = openai_text_embeddings(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Text vector embedding size =\", len(emb))\n",
    "emb[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [\n",
    "    \"Appollo 11 mission\",\n",
    "    \"A spaceship exploring the galaxy\",\n",
    "    \"A muddy playground near the ocean\",\n",
    "    \"A kid playing in the sand on the beach\",\n",
    "]\n",
    "\n",
    "text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combs = list(combinations(text_list, 2))\n",
    "\n",
    "for idx, (text1, text2) in enumerate(combs, start=1):\n",
    "    print(f\"{idx} Comparing\", text1, \"vs\", text2)\n",
    "    emb1 = openai_text_embeddings(text1)\n",
    "    emb2 = openai_text_embeddings(text2)\n",
    "    text_comparison(emb1, emb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image embeddings with Azure Computer vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import emoji\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "# Get Azure Computer Vision credentials\n",
    "azure_cv_endpoint = os.getenv(\"azure_cv_endpoint\")\n",
    "azure_cv_key = os.getenv(\"azure_cv_key\")\n",
    "\n",
    "version = \"?api-version=2023-02-01-preview&modelVersion=latest\"\n",
    "\n",
    "vec_img_url = (\n",
    "    azure_cv_endpoint + \"/computervision/retrieval:vectorizeImage\" + version\n",
    ")  # For doing the image vectorization\n",
    "\n",
    "vec_txt_url = (\n",
    "    azure_cv_endpoint + \"/computervision/retrieval:vectorizeText\" + version\n",
    ")  # For the prompt vectorization\n",
    "\n",
    "headers = {\n",
    "    \"Content-type\": \"application/json\",\n",
    "    \"Ocp-Apim-Subscription-Key\": azure_cv_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_embedding(imageurl):\n",
    "    \"\"\"\n",
    "    Embedding image using Azure Computer Vision 4\n",
    "    \"\"\"\n",
    "    image = {\"url\": imageurl}\n",
    "    r = requests.post(vec_img_url, data=json.dumps(image), headers=headers)\n",
    "    image_emb = r.json()[\"vector\"]\n",
    "\n",
    "    return image_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_comparison(vector1, vector2):\n",
    "    \"\"\"\n",
    "    Get cosine similarity value between two embedded vectors\n",
    "    \"\"\"\n",
    "    dot_product = sum(x * y for x, y in zip(vector1, vector2))\n",
    "    magnitude1 = math.sqrt(sum(x * x for x in vector1))\n",
    "    magnitude2 = math.sqrt(sum(x * x for x in vector2))\n",
    "    cos_similarity = round(dot_product / (magnitude1 * magnitude2), 10)\n",
    "\n",
    "    if cos_similarity == 1:\n",
    "        decision = \"identical\"\n",
    "        color_code = \"\\033[1;31;34m\"\n",
    "        emoticon = emoji.emojize(\":red_heart:\")\n",
    "    elif cos_similarity >= 0.8:\n",
    "        decision = \"similar\"\n",
    "        color_code = \"\\033[1;31;32m\"\n",
    "        emoticon = emoji.emojize(\":thumbs_up:\")\n",
    "    else:\n",
    "        decision = \"different\"\n",
    "        color_code = \"\\033[1;31;91m\"\n",
    "        emoticon = emoji.emojize(\":fire:\")\n",
    "\n",
    "    print(\n",
    "        f\"{emoticon} {color_code}{decision.upper()} images (cosine similarity = {cos_similarity})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = os.getenv(\"IMAGE_PATH\")+ \"i4.jpg?raw=true\"\n",
    "car1_emb = image_embedding(url1)\n",
    "\n",
    "plt.imshow(Image.open(requests.get(url1, stream=True).raw))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = os.getenv(\"IMAGE_PATH\")+ \"i4_2.jpg?raw=true\"\n",
    "car2_emb = image_embedding(url2)\n",
    "\n",
    "plt.imshow(Image.open(requests.get(url2, stream=True).raw))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 = os.getenv(\"IMAGE_PATH\")+ \"cat.jpg?raw=true\"\n",
    "cat_emb = image_embedding(url3)\n",
    "\n",
    "plt.imshow(Image.open(requests.get(url3, stream=True).raw))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 = os.getenv(\"IMAGE_PATH\")+ \"car.jpg?raw=true\"\n",
    "something = image_embedding(url4)\n",
    "\n",
    "plt.imshow(Image.open(requests.get(url4, stream=True).raw))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_comparison(car1_emb, car1_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_comparison(car1_emb, car2_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_comparison(car1_emb, cat_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_comparison(something, cat_emb)\n",
    "images_comparison(something, car2_emb)\n",
    "images_comparison(something, car1_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url5 = \"https://f1.imgci.com/PICTURES/CMS/17700/17793.jpg\"\n",
    "something2 = image_embedding(url5)\n",
    "\n",
    "plt.imshow(Image.open(requests.get(url5, stream=True).raw))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "url6 = \"https://www.shell.com.tr/motorists/motorsports/motorsport/_jcr_content/pagePromo/image.img.960.jpeg/1466016547071/ferrari-f1-car-crossing-the-finishing-line.jpeg\"\n",
    "something3 = image_embedding(url6)\n",
    "\n",
    "plt.imshow(Image.open(requests.get(url6, stream=True).raw))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "images_comparison(something2, something3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discover-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
